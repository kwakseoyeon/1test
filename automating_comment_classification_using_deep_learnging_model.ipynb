{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kwakseoyeon/1test/blob/master/automating_comment_classification_using_deep_learnging_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y15-TjhIQRfd",
        "outputId": "c653248a-ebaf-48d0-dd21-08dd9fc5e855"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmXPFEDm4rri"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\"text-classification\", model=\"sangrimlee/bert-base-multilingual-cased-nsmc\")\n",
        "\n",
        "def dl_model(input_text):\n",
        "    output = pipe(input_text)\n",
        "    if output[0]['label'] == 'positive':\n",
        "        return 1\n",
        "    else:\n",
        "        return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBn_GUpfaICs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f4ac03a-e95f-4d95-a475-c38c966fa829"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('tarr_train.txt', <http.client.HTTPMessage at 0x7a53823f5e70>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "import urllib.request\n",
        "\n",
        "urllib.request.urlretrieve(\n",
        "    \"https://raw.githubusercontent.com/tykimos/tykimos.github.io/master/warehouse/dataset/tarr_train.txt\",\n",
        "    filename=\"tarr_train.txt\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "082Wb7Pe7quv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "538b9527-d3af-4581-8ca5-80cb30b484fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "comment :  안 와봤으면 큰일날뻔; 여기 김치찌개는 진리네 ㅎㅎ\n",
            "actual class :  1\n",
            "predicted class :  0\n",
            "---------------\n",
            "comment :  사진보다 음식 portion이 좀 작은 거 아닌가요? 😐\n",
            "actual class :  0\n",
            "predicted class :  1\n",
            "---------------\n",
            "comment :  식사 중에 바퀴벌레가 나와서 기분이 엄청 나빴습니다.\n",
            "actual class :  0\n",
            "predicted class :  1\n",
            "---------------\n",
            "comment :  ㄴㅇㄱ... 여기서 이런 일을 겪을 줄이야...\n",
            "actual class :  0\n",
            "predicted class :  1\n",
            "---------------\n",
            "comment :  직원들 태도가 좀 불친절해요. 다음엔 다른 곳을 찾아볼게요.\n",
            "actual class :  0\n",
            "predicted class :  1\n",
            "---------------\n",
            "comment :  음... 나쁘진 않았지만, 특별히 좋지도 않았어요. 중간이라고 해야하나...\n",
            "actual class :  1\n",
            "predicted class :  0\n",
            "---------------\n",
            "comment :  그냥저냥? 뭐 크게 나쁘진 않았지만... 😐\n",
            "actual class :  0\n",
            "predicted class :  1\n",
            "---------------\n",
            "comment :  음식이 너무 짜지 않게 조절해 주셨으면 좋겠어요.\n",
            "actual class :  0\n",
            "predicted class :  1\n",
            "---------------\n",
            "comment :  저번에 갔을 때보다 맛이 좀 떨어진 것 같아요.\n",
            "actual class :  0\n",
            "predicted class :  1\n",
            "---------------\n",
            "comment :  떡볶이는 달고, 튀김은 기름져서 다시 오진 않을 것 같아요.\n",
            "actual class :  0\n",
            "predicted class :  1\n",
            "---------------\n",
            "comment :  여기 직원분들이 좀 불친절하시던데요? 🤨\n",
            "actual class :  0\n",
            "predicted class :  1\n",
            "---------------\n",
            "comment :  어릴 땐 여기 자주 왔는데, 맛이 변한 것 같아 아쉽네요.\n",
            "actual class :  0\n",
            "predicted class :  1\n",
            "---------------\n",
            "comment :  서비스만 좋았다면 별 5개를 줬을텐데, 아쉽습니다.\n",
            "actual class :  0\n",
            "predicted class :  1\n",
            "---------------\n",
            "comment :  전 너무 매웠어요. 다들 좋아하던데 맛의 차이인가 봐요.\n",
            "actual class :  0\n",
            "predicted class :  1\n",
            "---------------\n",
            "comment :  ㅋㅋ 여기 디저트 너무 달아요. 아쉬웠어요.\n",
            "actual class :  0\n",
            "predicted class :  1\n",
            "---------------\n",
            "comment :  와 진짜? 이런 곳에서 이런 경험을 할 줄이야.. 다신 안 올 거에요.\n",
            "actual class :  0\n",
            "predicted class :  1\n",
            "---------------\n",
            "comment :  햄버거 bun이 너무 퍽퍽함.\n",
            "actual class :  0\n",
            "predicted class :  1\n",
            "---------------\n",
            "comment :  마지막 방문 후로 퀄리티가 많이 떨어진 것 같아요. 아쉬워요.\n",
            "actual class :  0\n",
            "predicted class :  1\n",
            "---------------\n",
            "comment :  먹다 남긴 음식까지 포장해 주셔서 감사했습니다.\n",
            "actual class :  1\n",
            "predicted class :  0\n",
            "---------------\n",
            "comment :  저번에 왔을 때보다 서비스가 향상된 거 같아요! 계속 이렇게 유지해 주세요.\n",
            "actual class :  1\n",
            "predicted class :  0\n",
            "---------------\n",
            "comment :  이런.. 주문 잘못 가져와서 다시 기다렸어요.\n",
            "actual class :  0\n",
            "predicted class :  1\n",
            "---------------\n",
            "comment :  음식 나올 때까지 기다리는 시간이 너무 길어요. 개선 필요!\n",
            "actual class :  0\n",
            "predicted class :  1\n",
            "---------------\n",
            "comment :  음... 여기 리뷰 왜 이래? 사진으로 봤을 때랑 너무 다르네요.\n",
            "actual class :  0\n",
            "predicted class :  1\n",
            "---------------\n",
            "Accuracy: 92.33%\n",
            "{0, 1}\n",
            "{0, 1}\n",
            "\n",
            "Confusion Matrix:\n",
            "         Predicted:\n",
            "         긍정    부정\n",
            "Actual\n",
            "긍정      158    4    \n",
            "부정      19     119  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "def classify_text(input_text):\n",
        "    output = dl_model(input_text)\n",
        "    return output\n",
        "\n",
        "# 파일을 DataFrame으로 로드\n",
        "df = pd.read_csv('tarr_train.txt', delimiter='\\t')\n",
        "\n",
        "actual_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    comment = row['comment']\n",
        "    actual_label = row['label']\n",
        "    predicted_label = classify_text(comment)\n",
        "\n",
        "    actual_labels.append(actual_label)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "    if actual_label != predicted_label:\n",
        "        print(\"comment : \", comment)\n",
        "        print(\"actual class : \", actual_label)\n",
        "        print(\"predicted class : \", predicted_label)\n",
        "        print(\"---------------\")\n",
        "\n",
        "# 정확도 계산\n",
        "accuracy = accuracy_score(actual_labels, predicted_labels)\n",
        "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
        "\n",
        "print(set(actual_labels))\n",
        "print(set(predicted_labels))\n",
        "\n",
        "# Confusion matrix 계산\n",
        "cm = confusion_matrix(actual_labels, predicted_labels, labels=[1, 0])\n",
        "# Confusion matrix 표현\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(\"         Predicted:\")\n",
        "print(\"         긍정    부정\")\n",
        "print(\"Actual\")\n",
        "print(\"긍정      {:<5}  {:<5}\".format(cm[0][0], cm[0][1]))\n",
        "print(\"부정      {:<5}  {:<5}\".format(cm[1][0], cm[1][1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDhFSjNQaPYP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d519db67-ff49-49f3-e9f8-b2974ce58c8f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('tarr_sample_submit.txt', <http.client.HTTPMessage at 0x7a5259272560>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "urllib.request.urlretrieve(\n",
        "    \"https://raw.githubusercontent.com/tykimos/tykimos.github.io/master/warehouse/dataset/tarr_sample_submit.txt\",\n",
        "    filename=\"tarr_sample_submit.txt\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbYSVgb30uLS"
      },
      "outputs": [],
      "source": [
        "# 파일을 DataFrame으로 로드\n",
        "df_submit = pd.read_csv('tarr_sample_submit.txt', delimiter='\\t')\n",
        "\n",
        "predicted_labels = []\n",
        "\n",
        "# 각 row를 순회하며 코멘트를 분류\n",
        "for index, row in df_submit.iterrows():\n",
        "    comment = row['comment']\n",
        "    predicted_label = classify_text(comment)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# 예측된 레이블을 DataFrame에 추가\n",
        "df_submit['label'] = predicted_labels\n",
        "\n",
        "# 결과를 tarr_my_submit.txt로 저장\n",
        "df_submit[['id', 'comment', 'label']].to_csv('tarr_my_submit.txt', sep='\\t', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}