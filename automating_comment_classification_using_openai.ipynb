{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kwakseoyeon/1test/blob/master/automating_comment_classification_using_openai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai # openai ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HKd8CaCfWFc",
        "outputId": "698d4ec0-4a36-46a0-a245-56924521f036"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.14.3-py3-none-any.whl (262 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m262.9/262.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.14.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from google.colab import userdata\n",
        "\n",
        "openai.api_key = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "Bu7MbnanfXhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input_text : \"ì—¬ê¸° ìŒì‹ì€ ì–¸ì œ ì™€ë„ ì‹¤ë§ì‹œí‚¤ì§€ ì•Šì•„ìš”. ìµœê³ !\"\n",
        "\n",
        "system_prompt = \"\"\"\n",
        "Act as a classifier that accurately categorizes the sentiment of comments.\n",
        "Given a user-input comment,\n",
        "write '1' if the comment is positive, and '0' if the comment is negative.\n",
        "Output the INTEGER '1' or '0' ONLY, without any other text.\n",
        "\"\"\"\n",
        "\n",
        "def llm(input_text):\n",
        "\n",
        "    completion = openai.chat.completions.create(\n",
        "        model = \"gpt-3.5-turbo\",\n",
        "        messages =\n",
        "        [\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": input_text}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    output = completion.choices[0].message.content\n",
        "\n",
        "    # \"1ì…ë‹ˆë‹¤.\" ë¼ê³  ë‚˜ì˜¬ ìˆ˜ ìˆìŒ\n",
        "    if '1' in output:\n",
        "        return 1 # ê¸ì •\n",
        "\n",
        "    return 0 # ë¶€ì •"
      ],
      "metadata": {
        "id": "8f6DK6Zn40mf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "\n",
        "urllib.request.urlretrieve(\n",
        "    \"https://raw.githubusercontent.com/tykimos/tykimos.github.io/master/warehouse/dataset/tarr_train.txt\",\n",
        "    filename=\"tarr_train.txt\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzaHdDqBhXau",
        "outputId": "11f4e119-49db-4d0c-b047-c5c2454b7789"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('tarr_train.txt', <http.client.HTTPMessage at 0x78e421e85090>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "def classify_text(input_text):\n",
        "\n",
        "    output = llm(input_text)\n",
        "\n",
        "    return output\n",
        "\n",
        "# íŒŒì¼ì„ DataFrameìœ¼ë¡œ ë¡œë“œ\n",
        "df = pd.read_csv('tarr_train.txt', delimiter='\\t')\n",
        "\n",
        "actual_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "total = len(df)\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    comment = row['comment'] # ëŒ“ê¸€\n",
        "    actual_label = row['label'] # ê¸ì •/ë¶€ì •\n",
        "    predicted_label = classify_text(comment)\n",
        "\n",
        "    actual_labels.append(actual_label)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "    print(f\"[{index+1}]/[{total}]\")\n",
        "    print(\"comment : \", comment)\n",
        "    print(\"actual class : \", actual_label)\n",
        "    print(\"predicted class : \", predicted_label)\n",
        "    print(\"---------------\")\n",
        "\n",
        "    if index > 8:\n",
        "        break\n",
        "\n",
        "# ì •í™•ë„ ê³„ì‚°\n",
        "accuracy = accuracy_score(actual_labels, predicted_labels)\n",
        "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
        "\n",
        "# Confusion matrix ê³„ì‚°\n",
        "cm = confusion_matrix(actual_labels, predicted_labels, labels=[1, 0])\n",
        "# Confusion matrix í‘œí˜„\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(\"         Predicted:\")\n",
        "print(\"         ê¸ì •    ë¶€ì •\")\n",
        "print(\"Actual\")\n",
        "print(\"ê¸ì •      {:<5}  {:<5}\".format(cm[0][0], cm[0][1]))\n",
        "print(\"ë¶€ì •      {:<5}  {:<5}\".format(cm[1][0], cm[1][1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5fxQnd87y71",
        "outputId": "b7c751d0-dcc8-4e08-a4e1-239deabe3c8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "[1]/[300]\n",
            "comment :  ì—¬ê¸° ìŒì‹ì€ ì–¸ì œ ì™€ë„ ì‹¤ë§ì‹œí‚¤ì§€ ì•Šì•„ìš”. ìµœê³ !\n",
            "actual class :  1\n",
            "predicted class :  1\n",
            "---------------\n",
            "4\n",
            "[2]/[300]\n",
            "comment :  ì—¬ê¸° ë¼ë©˜ ì§„ì§œ ã„¹ã…‡ ë§›ìˆì–´ìš”. êµ­ë¬¼ì´ ì§„í•˜ê³  ë©´ë„ ì«„ê¹ƒí•´ì„œ ë„ˆë¬´ ì¢‹ì•˜ìŠµë‹ˆë‹¤.\n",
            "actual class :  1\n",
            "predicted class :  1\n",
            "---------------\n",
            "4\n",
            "[3]/[300]\n",
            "comment :  ì§„ì§œ ê¹”ë”í•˜ê³ , ë§›ë„ ì¢‹ì•˜ì–´ìš”. ì¶”ì²œí•©ë‹ˆë‹¤!\n",
            "actual class :  1\n",
            "predicted class :  1\n",
            "---------------\n",
            "0\n",
            "[4]/[300]\n",
            "comment :  ì™œ ì´ë ‡ê²Œ ìœ ëª…í•œì§€ ëª¨ë¥´ê² ìŒã…‹ã…‹ ã„¹ã…ˆã„· ë§›ì—†ìŒ\n",
            "actual class :  0\n",
            "predicted class :  0\n",
            "---------------\n",
            "4\n",
            "[5]/[300]\n",
            "comment :  ì¸ìƒ íƒ€ë¥´íŠ¸ë¥¼ ì—¬ê¸°ì„œ ë§Œë‚¬ì–´ìš”â¤ï¸ ë‹¬ì§€ ì•Šê³  ê³ ì†Œí•´ì„œ ì •ë§ ì¶”ì²œí•©ë‹ˆë‹¤!\n",
            "actual class :  1\n",
            "predicted class :  1\n",
            "---------------\n",
            "4\n",
            "[6]/[300]\n",
            "comment :  ë©”ë‰´ ì„¤ëª…ì„ ë„ˆë¬´ ì¹œì ˆí•˜ê²Œ í•´ì£¼ì…”ì„œ ê³ ë¥´ê¸° ìˆ˜ì›”í–ˆì–´ìš”.\n",
            "actual class :  1\n",
            "predicted class :  1\n",
            "---------------\n",
            "0\n",
            "[7]/[300]\n",
            "comment :  ì‚¬ì§„ê³¼ ìŒì‹ì´ ë„ˆë¬´ ë‹¬ë¼ì„œ ì‹¤ë§í–ˆìŠµë‹ˆë‹¤.\n",
            "actual class :  0\n",
            "predicted class :  0\n",
            "---------------\n",
            "4\n",
            "[8]/[300]\n",
            "comment :  ì£¼ë³€ì— ì¶”ì²œí•˜ë ¤ê³  ì‚¬ì§„ë„ ë§ì´ ì°ì—ˆì–´ìš”. ì¢‹ì•„ìš”!\n",
            "actual class :  1\n",
            "predicted class :  1\n",
            "---------------\n",
            "0\n",
            "[9]/[300]\n",
            "comment :  ì†”ì§íˆ...? ë§›ì´ ê·¸ë‹¥ì´ì—ìš”. ë¦¬ë·°ë‘ ë„ˆë¬´ ë‹¤ë¥´ë„¤.\n",
            "actual class :  0\n",
            "predicted class :  0\n",
            "---------------\n",
            "4\n",
            "[10]/[300]\n",
            "comment :  ì§„ì§œ ê°œê¿€ë§›..ã…  ë‹¤ë¥¸ê³³ ì•ˆê°€.\n",
            "actual class :  1\n",
            "predicted class :  1\n",
            "---------------\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Confusion Matrix:\n",
            "         Predicted:\n",
            "         ê¸ì •    ë¶€ì •\n",
            "Actual\n",
            "ê¸ì •      7      0    \n",
            "ë¶€ì •      0      3    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "urllib.request.urlretrieve(\n",
        "    \"https://raw.githubusercontent.com/tykimos/tykimos.github.io/master/warehouse/dataset/tarr_sample_submit.txt\",\n",
        "    filename=\"tarr_sample_submit.txt\",\n",
        ")"
      ],
      "metadata": {
        "id": "Oy2Z-N6Wh765",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "243fe62c-8c13-48c0-fcc9-a568f319e5e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('tarr_sample_submit.txt', <http.client.HTTPMessage at 0x78e421ea0670>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# íŒŒì¼ì„ DataFrameìœ¼ë¡œ ë¡œë“œ\n",
        "df_submit = pd.read_csv('tarr_sample_submit.txt', delimiter='\\t')\n",
        "\n",
        "predicted_labels = []\n",
        "\n",
        "total = len(df_submit)\n",
        "\n",
        "# ê° rowë¥¼ ìˆœíšŒí•˜ë©° ì½”ë©˜íŠ¸ë¥¼ ë¶„ë¥˜\n",
        "for index, row in df_submit.iterrows():\n",
        "    comment = row['comment']\n",
        "    predicted_label = classify_text(comment)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "    print(f\"[{index+1}]/[{total}]\")\n",
        "    print(\"comment : \", comment)\n",
        "    print(\"predicted class : \", predicted_label)\n",
        "    print(\"---------------\")\n",
        "\n",
        "    if index > 3:\n",
        "        break\n",
        "\n",
        "# ì˜ˆì¸¡ëœ ë ˆì´ë¸”ì„ DataFrameì— ì¶”ê°€\n",
        "#df_submit['label'] = predicted_labels\n",
        "\n",
        "# ê²°ê³¼ë¥¼ tarr_my_submit.txtë¡œ ì €ì¥\n",
        "#df_submit[['id', 'comment', 'label']].to_csv('tarr_my_submit.txt', sep='\\t', index=False)"
      ],
      "metadata": {
        "id": "KZQWKSFw3ocq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "802c0492-840b-4386-8384-6ad8637fa115"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]/[100]\n",
            "comment :  ì™„ì „ ë‚´ ìŠ¤íƒ€ì¼ì´ì—ìš”! ê°€ê²©ë„ ì ë‹¹í•˜ê³  ìœ„ì¹˜ë„ ì¢‹ê³ ğŸ‘Œ\n",
            "predicted class :  1\n",
            "---------------\n",
            "[2]/[100]\n",
            "comment :  ë§›ìˆê¸´ í•œë° ì–‘ì´ ë„ˆë¬´ ì ì–´ì„œ ì¢€... ã… \n",
            "predicted class :  0\n",
            "---------------\n",
            "[3]/[100]\n",
            "comment :  ì™„ì „ ë‚´ ìŠ¤íƒ€ì¼ì´ì—ìš” ã… ã…  ì—¬ê¸° ë§¤ì¥ ë¶„ìœ„ê¸°ë„ ì´ì¨\n",
            "predicted class :  1\n",
            "---------------\n",
            "[4]/[100]\n",
            "comment :  í•œêµ­ì˜ ì „í†µ ìŒì‹ì„ ì˜ í‘œí˜„í•œ ê²ƒ ê°™ì•„ìš”. í–¥í† ìŒì‹ì˜ ì •ì·¨ê°€ ëŠê»´ì ¸ ì¢‹ì•˜ìŠµë‹ˆë‹¤.\n",
            "predicted class :  1\n",
            "---------------\n",
            "[5]/[100]\n",
            "comment :  ì„œë¹™í•˜ëŠ” ë¶„ì´ ì¢€ ë¶ˆì¹œì ˆí•´ì„œ ê¸°ë¶„ì´ ì¢€ ê·¸ë¬ì–´ìš”.\n",
            "predicted class :  0\n",
            "---------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y-4ZHGU3Nk8_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}